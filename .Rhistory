# rm(list = ls())
#library(devtools)
install_github("statsmaths/glmgen", subdir="R_pkg/glmgen")
# rm(list = ls())
library(devtools)
# rm(list = ls())
install.packages("devtools")
library(devtools)
install_github("statsmaths/glmgen", subdir="R_pkg/glmgen")
library(glmgen)
library(plotly)
library(tidyverse)
library(extraDistr)
scenario0(500, 5, 0.5, TRUE)
scenario0 <- function(n, d, tau, plots = FALSE) {
# Scenario 0
# g_0 is piecewise constant function alternating between 1 and -1,
# at j + 2 breakpoints
# x drawn randomly from uniform distribution for each component
# f_0 <- a_j * piecewise_function - b_j with b_j such that mean(f_0) = 0
# and a_j such that norm(f_0) = 1
if (length(n) != 1 || length(d) != 1 || length(tau) != 1) {
stop("Scenario function is only suitable for a single scenario.\n
Please ensure inputs are each scalar values.")
}
x_list <- matrix(NA, nrow = d, ncol = n)
y_list <- matrix(NA, nrow = d, ncol = n)
piecewise_constant <- function(x, breakpoints, values) {
intervals <- findInterval(x, breakpoints)
return(values[intervals])
}
for (j in 1:d) {
x_list[j, ] <- runif(n, 0, 1)
# Define breakpoints for piecewise constant function
breakpoints <- seq(0, 1, length.out = j + 2)^2
values <- rep(c(1, -1), length.out = j + 1)  # alternating between 1 and -1
# Piecewise constant function
g_0 <- piecewise_constant(x_list[j, ], breakpoints, values)
b_j <- mean(g_0)
a_j <- 1 / (norm(g_0 - b_j, type = "2") / sqrt(n))
y_list[j, ] <- a_j * g_0 - a_j * b_j
if (plots) {
filename <- paste(getwd(), '/sce0_plot_', j, '.png', sep = '')
png(filename)
plot(y_list[j, ]~x_list[j, ], main = paste('Scenario 0 j =', j), xlab = 'x', ylab = 'y')
dev.off()
}
}
# Sum of each column of y_list
y_star <- colSums(y_list)
# T(3) errors
y <- y_star + rt(n, 3)
y_star_q <- y_star + qt(tau, 3)
if (tau != 0.5) { warning("Tau != 0.5. Only use output for QATF!")}
return(list(x_list, y, y_star_q))
}
scenario0(500, 5, 0.5, TRUE)
scenario0(500, 2, 0.5, TRUE)
breakpoints <- seq(0, 1, length.out = 8)^2
# Define the function using modular math
f <- function(x) {
# Find which interval x belongs to by checking which breakpoint it exceeds
interval <- findInterval(x, breakpoints)
# Alternate between 0 and 1 using modular math
return((interval %% 2) == 1) * 1  # Mod 2 to alternate, multiply by 1 to get 0/1 output
}
# Example usage:
x <- seq(0, 1, by = 0.05)
f(x)
# Example usage:
x <- seq(0, 1, length.out = 100)
plot(f(x)~x)
findInterval(x, breakpoints)
# Define the breakpoints
breakpoints <- seq(0, 1, length.out = 8)^2
# Define the function using modular math
f <- function(x) {
# Find which interval x belongs to, and ensure it stays within the range
interval <- pmin(findInterval(x, breakpoints), length(breakpoints) - 1)
# Alternate between 0 and 1 using modular math
return((interval %% 2) == 1) * 1  # Mod 2 to alternate, multiply by 1 to get 0/1 output
}
# Example usage:
x <- seq(0, 1, length.out = 100)
plot(f(x) ~ x)
# Example usage:
x <- seq(0, 1, length.out = 100)
plot(f(x) ~ x)
beta <- lapply(x, f)
f_bar <- mean(unlist(beta))
beta <- lapply(beta, function(b, adj) b - adj, f_bar)
plot(beta)
beta
plot(unlist(beta))
# Define the function using modular math
f <- function(x) {
breakpoints <- seq(0, 1, length.out = 8)^2
interval <- pmin(findInterval(x, breakpoints), length(breakpoints) - 1)
return((interval %% 2) == 1) * 2  -1
}
# Define the function using modular math
f <- function(x) {
breakpoints <- seq(0, 1, length.out = 8)^2
interval <- pmin(findInterval(x, breakpoints), length(breakpoints) - 1)
return((interval %% 2) == 1) * 2 - 1
}
# Example usage:
x <- seq(0, 1, length.out = 100)
plot(f(x) ~ x)
beta <- lapply(x, f)
f_bar <- mean(unlist(beta))
beta <- lapply(beta, function(b, adj) b - adj, f_bar)
plot(unlist(beta))
# Define the function using modular math
f <- function(x) {
breakpoints <- seq(0, 1, length.out = 8)^2
interval <- pmin(findInterval(x, breakpoints), length(breakpoints) - 1)
return(((interval %% 2) == 1) * 2 - 1)
}
# Example usage:
x <- seq(0, 1, length.out = 100)
plot(f(x) ~ x)
beta <- lapply(x, f)
f_bar <- mean(unlist(beta))
beta <- lapply(beta, function(b, adj) b - adj, f_bar)
plot(unlist(beta))
# Define the function using modular math
f <- function(x) {
breakpoints <- seq(0, 1, length.out = 9)^2
interval <- pmin(findInterval(x, breakpoints), length(breakpoints) - 1)
return(((interval %% 2) == 1) * 2 - 1)
}
# Example usage:
x <- seq(0, 1, length.out = 100)
plot(f(x) ~ x)
beta <- lapply(x, f)
f_bar <- mean(unlist(beta))
beta <- lapply(beta, function(b, adj) b - adj, f_bar)
plot(unlist(beta))
# Define the function using modular math
f <- function(x) {
breakpoints <- seq(0, 1, length.out = 9)^2
interval <- pmin(findInterval(x, breakpoints), length(breakpoints) - 1)
return(((interval %% 2) == 1) * 1)
}
# Example usage:
x <- seq(0, 1, length.out = 100)
plot(f(x) ~ x)
beta <- lapply(x, f)
f_bar <- mean(unlist(beta))
beta <- lapply(beta, function(b, adj) b - adj, f_bar)
plot(unlist(beta))
# Define the function using modular math
f <- function(x) {
ifelse(x <= 0.4, 2.5 * x,
ifelse(x <= 0.6, 45 * x - 17,
ifelse(x <= 0.8, -40 * x + 34,
30 * x - 22)))
}
# Example usage:
x <- seq(0, 1, length.out = 100)
plot(f(x) ~ x)
beta <- lapply(x, f)
f_bar <- mean(unlist(beta))
beta <- lapply(beta, function(b, adj) b - adj, f_bar)
plot(unlist(beta))
dotPlot?
?dotPlot
dotPlot
?dotplot
plot
?plot
?Plot
?dotPlot
?dotchart
setwd("~/Desktop/Research/MRDPG/CPDmrdpg")
library(rTensor)
source("SBS.R")
get_blockwise_const_mat <- function(n, n_c, p_1, p_2){
P = matrix(p_1, n, n)
size_c = floor(n / n_c)
for (k in 1:n_c){
if (k < n_c){
P[(1 + size_c*(k-1)):(size_c * k), (1 + size_c*(k-1)):(size_c * k)] = p_2
} else {
P[(1 + size_c*(n_c-1)):n, (1 + size_c*(n_c-1)):n] = p_2
}
}
return(P)
}
get_sbm_params <- function(n, L, n_c=c(4, 4), flip_layer=TRUE){
probability_1 = array(NA, c(n, n, L))
probability_2 = array(NA, c(n, n, L))
prob = seq(0,1,  1/(4*L))
for (layer in 1: L)
{
p_1 = runif(1, prob[2*L+layer], prob[2*L+layer+1])
p_2 = runif(1, prob[3*L+layer], prob[3*L+layer+1])
P = get_blockwise_const_mat(n, n_c[1], p_1, p_2)
probability_1[, , layer] = P
P = get_blockwise_const_mat(n, n_c[2], p_1, p_2)
if (flip_layer){
probability_2[, , L - layer + 1] = P
} else {
probability_2[, , layer] = P
}
}
return(list(probability_1, probability_2))
}
#### sbm directed
generate_tensor_probability_directed <- function(n_1, n_2, L, probability){
dim_ = c(n_1, n_2, L)
A = array(NA,dim_)
for (layer in 1: L)
{
A[, , layer] = matrix(rbinom(matrix(1,n_1,n_2),matrix(1,n_1,n_2), probability[ , , layer]),n_1,n_2)
}
return(A)
}
A.tensor <- array(NA, c(150, 50, 50, 4))
sbm_params <- get_sbm_params(n=50, L=4, n_c=c(4, 4), flip_layer=TRUE)
probability_1 = sbm_params[[1]]
probability_2 = sbm_params[[2]]
for(t_iter in 1:50) A.tensor[t_iter,,,] <- generate_tensor_probability_directed(n_1=50, n_2=50, L=4, probability_1)
for(t_iter in 51:100) A.tensor[t_iter,,,] <- generate_tensor_probability_directed(n_1=50, n_2=50, L=4, probability_2)
for(t_iter in 101:150) A.tensor[t_iter,,,] <- generate_tensor_probability_directed(n_1=50, n_2=50, L=4, probability_1)
diff_frobenius <- function(A, B) sum((A - B)^2)^0.5
Hetero_PCA_test <- function(Y, r, tmax = 20, vartol = 1e-6){
N_t = Y
r = min(c(r, dim(N_t)))
diag(N_t) = 0
U_t = matrix(NA, nrow = dim(Y)[1], r)
t = 1
approx = -1
while(t <= tmax){ # Stop criterion: convergence or maximum number of iteration reached
temp = svd(N_t)
U_t = temp$u[,1:r]
V_t = temp$v[,1:r]
if (r > 1){
tilde_N_test_t = U_t %*% diag(temp$d[1:r]) %*% t(V_t)
}
else{
tilde_N_test_t = temp$d[1] * U_t %*% t(V_t)
}
N_test_new = N_t
diag(N_test_new) = diag(tilde_N_test_t)
N_t = N_test_new
svector = diag(tilde_N_test_t)
if (abs(sum(svector^2) - approx) > vartol){
t = t+1
approx = sum(svector^2)
}
else {
break
}
}
return(U_t)
}
Tensor_Hetero_PCA_test <- function(Y, r, tmax = 20){
p = dim(Y)
d = length(p)
U_0 = list()
for (i in 1:d){
MY = k_unfold(Y, i)@data
MY_Hetero_PCA = Hetero_PCA_test(MY %*% t(MY), r[i], tmax)
U_0 = c(U_0, list(MY_Hetero_PCA))
}
return(U_0)
}
estimate_thpca <- function(Y.tensor, hat.rank, tmax = 20){
U.hat = Tensor_Hetero_PCA_test(Y.tensor, hat.rank, tmax)
P.U1 = U.hat[[1]]%*%t(U.hat[[1]])
P.U2 = U.hat[[2]]%*%t(U.hat[[2]])
P.U3 = U.hat[[3]]%*%t(U.hat[[3]])
Y.hat = ttm(ttm(ttm(Y.tensor, P.U1, 1), P.U2, 2), P.U3, 3)
P_hat  = Y.hat@data
P_hat[P_hat > 1]  = 1
P_hat[P_hat < 0]  = 0
return(P_hat)
}
CUSUM_frobenius <- function(obj, s, e, t, rank) {
print(paste0("s = ", s, ", e = ", e, ", t = ", t, "."))
if ((t - s) == 1) {
sum_s_t <- as.tensor(A.tensor[(s+1):t, , , ])
} else {
sum_s_t  <- (1/(t - s)) * as.tensor( apply(A.tensor[(s+1):t, , , ], c(2, 3, 4), sum) )
}
if ((e - t )== 1) {
sum_t_e <- as.tensor(A.tensor[(t+1):e, , , ])
} else {
sum_t_e <- (1/(e - (t))) * as.tensor( apply(A.tensor[(t+1):e, , , ], c(2, 3, 4), sum) )
}
P_s_t  <- estimate_thpca(sum_s_t, rank, tmax = 20)
P_t_e <- estimate_thpca(sum_t_e, rank, tmax = 20)
return(diff_frobenius(P_s_t, P_t_e))
}
CUSUM_layer <- function(obj, s, e, t, rank) {
# Implement CUSUM layer
}
hat.rank <- c(15, 15, 15)
s <- 0
e <- 150
frobenius_holder <- numeric(149)
for(t in 2:148){
# print(paste0("s = ", s, ", e = ", e, ", t = ", t, "."))
# if ((t - s) == 1) {
#   sum_s_t <- as.tensor(A.tensor[(s+1):t, , , ])
# } else {
#   sum_s_t  <- (1/(t - s)) * as.tensor( apply(A.tensor[(s+1):t, , , ], c(2, 3, 4), sum) )
# }
#
# if ((e - t )== 1) {
#   sum_t_e <- as.tensor(A.tensor[(t+1):e, , , ])
# } else {
#   sum_t_e <- (1/(e - (t))) * as.tensor( apply(A.tensor[(t+1):e, , , ], c(2, 3, 4), sum) )
# }
#
# P_s_t  <- estimate_thpca(sum_s_t, hat.rank, tmax = 20)
# P_t_e <- estimate_thpca(sum_t_e, hat.rank, tmax = 20)
#
# frobenius_holder[t] <- (diff_frobenius(P_s_t, P_t_e))
frobenius_holder[t] <- CUSUM_frobenius(A.tensor, s, e, t, hat.rank)
}
plot(1:149, frobenius_holder, type='l')
intervals <- construct_intervals(150, 1/2, 4)
results_one <- cusum_on_intervals(CUSUM_frobenius, A.tensor, c(30, 38), rank = hat.rank)
results_all <- cusum_on_intervals(CUSUM_frobenius, A.tensor, intervals, rank = hat.rank)
# Pass in CUSUM results (as a matrix) to save computation
results <- seeded_binary_seg(CUSUM_frobenius, A.tensor, 150, CUSUM_res = results_all,
threshold = c(22, 18, 16), method = "Greedy", rank = hat.rank)
results[[2]]$results
results[[3]]$results
source("SBS.R")
intervals <- construct_intervals(150, 1/2, 4)
s_results_all <- cusum_on_intervals(CUSUM_frobenius, A.tensor, intervals, rank = hat.rank)
results[[3]]$results
# Pass in CUSUM results (as a matrix) to save computation
results <- seeded_binary_seg(CUSUM_frobenius, A.tensor, 150, CUSUM_res = results_all,
threshold = c(22, 19, 16), method = "Greedy", rank = hat.rank)
results[[3]]$results
s_results[[3]]$results
s_results[[3]]$results
s_results
# Pass in CUSUM results (as a matrix) to save computation
s_results <- seeded_binary_seg(CUSUM_frobenius, A.tensor, 150, CUSUM_res = s_results_all,
threshold = c(22, 18, 16), method = "Greedy", rank = hat.rank)
s_results
# Pass in CUSUM results (as a matrix) to save computation
s_results <- seeded_binary_seg(CUSUM_frobenius, A.tensor, 150, CUSUM_res = s_results_all,
threshold = c(22, 18, 16), method = "Narrowest", rank = hat.rank)
s_results
